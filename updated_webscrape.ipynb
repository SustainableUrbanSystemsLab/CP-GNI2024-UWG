{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Function to scrape data for a single day\n",
    "def scrape_data_for_date(date_str):\n",
    "    # Set up Chrome options\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "    chrome_options.add_argument(\"--disable-gpu\")  # Disable GPU acceleration\n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")  # Set window size\n",
    "    \n",
    "    # Initialize the WebDriver with the headless options\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    \n",
    "    # Construct the URL with the current date\n",
    "    url = f\"https://www.wunderground.com/dashboard/pws/KGAATLAN216/table/{date_str}/{date_str}/daily\"\n",
    "    \n",
    "    # Open the URL\n",
    "    driver.get(url)\n",
    "    \n",
    "    try:\n",
    "        # Wait for the table body element to be present in the DOM\n",
    "        tbody = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//html/body/app-root/app-dashboard/one-column-layout/wu-header/sidenav/mat-sidenav-container/mat-sidenav-content/div[2]/section/section[1]/div[1]/div/section/div/div/div/lib-history/div[2]/lib-history-table/div/div/div/table'))\n",
    "        )\n",
    "        \n",
    "        # Extract data from the table\n",
    "        l = []\n",
    "        table_rows = tbody.find_elements(By.XPATH, './/tr')\n",
    "\n",
    "        for row in table_rows:\n",
    "            row_data = [cell.text for cell in row.find_elements(By.XPATH, './/td')]\n",
    "            l.append(row_data)\n",
    "        \n",
    "        # Convert the data into a pandas DataFrame\n",
    "        df = pd.DataFrame(l)\n",
    "        df['Date'] = date_str\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for date {date_str}: {e}\")\n",
    "        df = pd.DataFrame()  # Return an empty DataFrame in case of error\n",
    "\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "    \n",
    "    print(f\"Day {date_str} is done\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = datetime.strptime(\"2023-01-01\", \"%Y-%m-%d\")\n",
    "end_date = datetime.strptime(\"2023-01-02\", \"%Y-%m-%d\")\n",
    "\n",
    "# Create a list of all dates to process\n",
    "dates = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "date_strings = [date.strftime(\"%Y-%m-%d\") for date in dates]\n",
    "\n",
    "# Scrape data sequentially for each date\n",
    "results = [scrape_data_for_date(date_str) for date_str in date_strings]\n",
    "g \n",
    "# Concatenate all the DataFrames together\n",
    "all_data = pd.concat(results, ignore_index=True)\n",
    "\n",
    "print(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
